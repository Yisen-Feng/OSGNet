dataset_name: ego4d_multitask
track: goal_step
devices: cuda:0
train_split: ['training']
val_split: ['validation']
model_name: MultiTaskArch
dataset: {
  json_file: ego4d_data/goalstep_data/ego4d_goal_step_val_v2_lemma.jsonl,
  train_jsonl_file: ego4d_data/goalstep_data/clip/ego4d_goal_step_train_v2.jsonl,
  val_jsonl_file: ego4d_data/goalstep_data/ego4d_goal_step_val_v2_lemma.jsonl,
  video_feat_dir: /root/autodl-tmp/data/ego4d/goalstep/video_feature/internvideo_clip_lmdb,
  text_feat_dir: /root/autodl-tmp/data/ego4d/goalstep/clip_query_lmdb,
  val_text_feat_dir: /root/autodl-tmp/data/ego4d/goalstep/clip_query_lmdb,
  object_feat_dir: /root/autodl-tmp/data/ego4d/goalstep/co-detr/clip-class-lmdb,
  classname_feat_dir: /root/autodl-tmp/data/ego4d/nlq/classname-clip-base/a_photo_of.pt,
  classname_feat_concat: only,
  object_feat_type: class-score,
  lavila_caption_dir: /root/autodl-tmp/data/ego4d/goalstep/lavila-64/,
  num_classes: 1,
  input_vid_dim: 2304,
  input_txt_dim: 512,
  feat_stride: 16.0,
  num_frames: 16.0,
  default_fps: 30,
  max_seq_len: 9216,
}
model: {
  text_encoder_cfg: [
    {
      layer_type: MaskedConv1DLayer,
      layer_num: 1,
      layer_cfg: {
        num_layer: 2,
        n_in: 512,
        act: relu,
      }
      
    },
    {
      layer_type: TransformerBlock,
      layer_num: 4,
      layer_cfg: {
        n_head: 4,
        n_embd: 512,
        path_pdrop: 0.1
      }
    }
  ],
  obj_encoder_cfg: [
    {
      layer_type: MaskedConv1DLayer,
      layer_num: 1,
      layer_cfg: {
        num_layer: 2,
        n_in: 512,
        act: relu,
      }
      
    },
    {
      layer_type: ObjectEncoderBlock,
      layer_num: 4,
      layer_cfg: {
        n_embd: 512,
        path_pdrop: 0.1
      }
      
    }
  ],
  video_encoder_cfg: [
    {
      layer_type: MaskedConv1DLayer,
      layer_num: 1,
      layer_cfg: {
        num_layer: 2,
        n_in: 2304,
        n_hidden: 512,
        n_out: 512,
        kernel_size: 3,
        act: relu,
      }
      
    },
    {
      layer_type: ObjectMambaBlock,
      layer_num: 4,
      layer_cfg: {
        n_head: 4,
        n_embd: 512,
        path_pdrop: 0.1,
        mamba_arch: ['bimamba1','mlp','obj']
      }
    }
  ],
  multiscale_encoder_cfg: [
    {
      layer_type: TransformerBlock,
      layer_num: 6,
      layer_cfg: {
        n_head: 4,
        n_embd: 512,
        n_ds_strides: [2,2],
        mha_win_size: 9,
        path_pdrop: 0.1
      }
    },
    {
      layer_type: FPNLayernorm,
      layer_num: 1,
      layer_cfg: {
        in_channels: [512,512,512,512,512,512,512],
        out_channel: 512,

      }
    }
  ],
  tasks: [
    NLQ,VTM
  ],
  generator: {
    generator_type: point,
    
  },
  nlq_heads_cfg: {
    cls_head_cfg: {
      input_dim: 512,
      feat_dim: 512,
      num_classes: 1,
      kernel_size: 3,
      prior_prob: 0.01,
      with_ln: True,
      num_layers: 3,
      empty_cls: []
    },
    reg_head_cfg: {
      input_dim: 512,
      feat_dim: 512,
      fpn_levels: 7,
      kernel_size: 3,
      with_ln: True,
      num_layers: 3,
    },
    loss_normalizer_momentum: 0.9,
    loss_normalizer: 200,
    train_label_smoothing: 0.1,
    reg_loss_weight: 1.0,
    center_sample_radius: 1.5,
    pre_nms_thresh: 0.001,
    pre_nms_topk: 2000,
    duration_thresh: 0.001,
    iou_threshold: 0.1,
    min_score: 0.001,
    max_seg_num: 5,
  },
  vtm_heads_cfg: {
    shot_aggregator_cfg: {
      layer_type: QFormerLayer,
      layer_cfg: {
        self_mixer_cfg: {
          block_type: MaskedMHCA,
          block_cfg: {
            n_head: 4,
            n_embd: 512,
          }
        },
        cross_mixer_cfg: {
          block_type: MaskedMHA,
          block_cfg: {
            n_head: 4,
            n_embd: 512,
          }
        },
        path_pdrop: 0.1,
        query_num: 5,
        num_layer: 1
      }

    },
    similarity_head_cfg: {
      layer_type: Cosine,
      layer_cfg: {
        x_dim: 512,
        y_dim: 512,
        con_dim: 512
      }
    },
    loss_weight: 1.5
  },
  max_shot_num: 3400,
  max_query: 560,
  max_buffer_len_factor: 4.0,
  use_abs_pe: True,
  regression_range: [[0, 4], [2, 8], [4, 16], [8, 32], [16, 64], [32, 128],[64, 10000]],
}
opt: {
  learning_rate: 0.0002,
  backbone_lr_weight: 1,
  epochs: 6,
  warmup_epochs: 4,
  weight_decay: 0.05,
}
loader: {
  batch_size: 1,
  num_workers: 1,
}
train_cfg: {
  init_loss_norm: 200,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  label_smoothing: 0.1,
  droppath: 0.1,
  loss_weight: 1.0,
  mamba_arch: ['bimamba1','mlp','obj']
}
test_cfg: {
  voting_thresh: 0.9,
  pre_nms_topk: 2000,
  # max of 50 predictions per video
  max_seg_num: 5,
  min_score: 0.001,
  nms_sigma : 0.75,
  duration_thresh: 0.001,
  test_num: 1,
  test_start_epoch: 2
}
output_folder: /root/autodl-tmp/model/GroundNLQ/goalstep/
